{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83849b03",
   "metadata": {},
   "source": [
    "# 线性代数\n",
    "标量由只有一个元素的张量表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a01296a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.tensor([3])\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3aae7a8",
   "metadata": {},
   "source": [
    "### 访问张量的长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0c3a7f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3405d2",
   "metadata": {},
   "source": [
    "### 矩阵的转置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c40c99c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11],\n",
       "         [12, 13, 14, 15],\n",
       "         [16, 17, 18, 19]]),\n",
       " tensor([[ 0,  4,  8, 12, 16],\n",
       "         [ 1,  5,  9, 13, 17],\n",
       "         [ 2,  6, 10, 14, 18],\n",
       "         [ 3,  7, 11, 15, 19]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(20).reshape(5,4)\n",
    "A,A.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8b91c2",
   "metadata": {},
   "source": [
    "向量是标量的推广，矩阵是向量的推广。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fa0157e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11],\n",
       "        [12, 13, 14, 15],\n",
       "        [16, 17, 18, 19]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = A.clone()\n",
    "B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5714dead",
   "metadata": {},
   "source": [
    "### Hadamard积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6baa6d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   1,   4,   9],\n",
       "        [ 16,  25,  36,  49],\n",
       "        [ 64,  81, 100, 121],\n",
       "        [144, 169, 196, 225],\n",
       "        [256, 289, 324, 361]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A * B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95534d0",
   "metadata": {},
   "source": [
    "### 加和。\n",
    "实质上是广播机制。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd14c644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2,  3,  4,  5],\n",
       "        [ 6,  7,  8,  9],\n",
       "        [10, 11, 12, 13],\n",
       "        [14, 15, 16, 17],\n",
       "        [18, 19, 20, 21]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 2\n",
    "a + A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601383cc",
   "metadata": {},
   "source": [
    "当然，表示任意形状张量的元素和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2853c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 5, 4]),\n",
       " tensor(780),\n",
       " tensor([[[ 0,  1,  2,  3],\n",
       "          [ 4,  5,  6,  7],\n",
       "          [ 8,  9, 10, 11],\n",
       "          [12, 13, 14, 15],\n",
       "          [16, 17, 18, 19]],\n",
       " \n",
       "         [[20, 21, 22, 23],\n",
       "          [24, 25, 26, 27],\n",
       "          [28, 29, 30, 31],\n",
       "          [32, 33, 34, 35],\n",
       "          [36, 37, 38, 39]]]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(20*2).reshape(2,5,4)\n",
    "A.shape,A.sum(),A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42efcad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[20, 22, 24, 26],\n",
       "         [28, 30, 32, 34],\n",
       "         [36, 38, 40, 42],\n",
       "         [44, 46, 48, 50],\n",
       "         [52, 54, 56, 58]]),\n",
       " torch.Size([5, 4]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_sum_axis0 = A.sum(axis=0)\n",
    "A_sum_axis0,A_sum_axis0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d96831f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 40,  45,  50,  55],\n",
       "         [140, 145, 150, 155]]),\n",
       " torch.Size([2, 4]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_sum_axis1 = A.sum(axis=1)\n",
    "A_sum_axis1,A_sum_axis1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a26ab22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([180, 190, 200, 210])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.sum(axis=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19f7691",
   "metadata": {},
   "source": [
    "计算总和或均值的时候保持轴不变,有利于进行广播。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a550dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 40,  45,  50,  55]],\n",
       " \n",
       "         [[140, 145, 150, 155]]]),\n",
       " tensor([[[0.0000, 0.0222, 0.0400, 0.0545],\n",
       "          [0.1000, 0.1111, 0.1200, 0.1273],\n",
       "          [0.2000, 0.2000, 0.2000, 0.2000],\n",
       "          [0.3000, 0.2889, 0.2800, 0.2727],\n",
       "          [0.4000, 0.3778, 0.3600, 0.3455]],\n",
       " \n",
       "         [[0.1429, 0.1448, 0.1467, 0.1484],\n",
       "          [0.1714, 0.1724, 0.1733, 0.1742],\n",
       "          [0.2000, 0.2000, 0.2000, 0.2000],\n",
       "          [0.2286, 0.2276, 0.2267, 0.2258],\n",
       "          [0.2571, 0.2552, 0.2533, 0.2516]]]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_A = A.sum(axis=1,keepdims=True)\n",
    "sum_A,A/sum_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de5301d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11],\n",
       "         [12, 13, 14, 15],\n",
       "         [16, 17, 18, 19]],\n",
       "\n",
       "        [[20, 22, 24, 26],\n",
       "         [28, 30, 32, 34],\n",
       "         [36, 38, 40, 42],\n",
       "         [44, 46, 48, 50],\n",
       "         [52, 54, 56, 58]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.cumsum(axis=0) # 累加"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b698e642",
   "metadata": {},
   "source": [
    "### 矩阵的点乘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5f6de383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1., 2., 3.]), tensor([1., 1., 1., 1.]), tensor(6.))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(4,dtype=torch.float32)\n",
    "y = torch.ones(4,dtype=torch.float32)\n",
    "x,y,torch.dot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b0f8787c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.,  6.,  6.],\n",
       "        [22., 22., 22.],\n",
       "        [38., 38., 38.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(12,dtype=torch.float32).reshape(3,4)\n",
    "B = torch.ones(12,dtype=torch.float32).reshape(4,3)\n",
    "torch.mm(A,B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76483af7",
   "metadata": {},
   "source": [
    "### 范数\n",
    "向量或者矩阵的长度\n",
    "对向量而言：\n",
    "L1：绝对值之和\n",
    "L2:平方和开根\n",
    "对矩阵而言：\n",
    "平方和开根"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b165269",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = torch.tensor([3.0,-4.0])\n",
    "torch.norm(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855a4c4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch for Deeplearning",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
